{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr. Ebbini Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signal, when you ocmpute a propagation into our out of element, you actually sum those sub-element contributions before you launch. For computation purposes.\n",
    "\n",
    "fullArray - is 3xsome number of sub elements x 32. This 3D array contains the coordinates of all subelements. Must feed into array geometry.\n",
    "normCenter - 3x32 center of each element\n",
    "normDir - 3x32 normal vector coming out of each element (shows directivity)\n",
    "dmua_decault_coeff - 64x1\n",
    "\n",
    "This is for prefiltering the data. We have recently been emphacizing using Butterworth filters. Good for tuture implementations. A/D data may have nois, limit bandwidth from 2-20 MHz. \n",
    "\n",
    "Start by pushing into base\n",
    "cudaEnginge('base','push','fullArray,normCenter,normDir');\n",
    "\n",
    "The same philosophy is applied here. Define an array. These are extrememly useful images. Imaging mostly in water. 1480 is the speed. Based on what we know for the experiment, we need to think about these parameters. WE can define these as parameters and share them tothe registers:\n",
    "cudaEmgine('reg','/Imaging',sprintf('SoundSpeed=%f',SpeedofSound));\n",
    "\n",
    "cudaEngine('reg','/Imaging/Engines/Beamformer','ROI=[29, 29, -10, 20]'Fs=50'CustomGrid=false'Mode=0'AlineOffset=50');\n",
    "29 is the nearest point on the grid.\n",
    "Alineoffset - there is a delay of 50 samples before A/D starts. This is important during longer sequences. Even if we have a grid that we designed, we may not have incorperated the dleays in the samplings. In matlab now, We'd like to look at the multiband analysis of the data.\n",
    "\n",
    "If we were doing specle tracking, there is lots of reverberation at 3MHz. If we look at 3MHz, we see a lot of artifacts. The echo there is going to be dominated. It has nothing to do with what's in the water. The image should be dark except with what's in the water to do good specle tracking. The point is that not all frequencies are created equal. Relative intensity of hydrophone compared to the skull is a measure of transmission. Ultimately, transmission and reflection tests going forward.\n",
    "\n",
    "If we beamform at 1480, we get good reconstruction up to the skull; but alignment and things within the brain are not that great. We end up using 1520 because aligning things within the brain is better. We'd like to start using this capability. We feed the program Rsin(theta) grid. Dalon didn't have time to modify the grid. The program accepts the grid with ipc, and will beamform with that grid. The picture will look distorted on his screen. \n",
    "\n",
    "Precomputed a grid. Design arrays based on geometry of the skull helps to capture the geometry of the array. Capture the boundaries of the skull. MOdify the grid based on the geometry of the skull. Subtomography, but localized. Because this is SA data, we get fairly accurate estimate from the points in space. We can deal with the echo in space. It is a measure of tissue property. Most accurate is tomographic reconstruction.Still use real time beamforming imaging. Get better images.\n",
    "\n",
    "Better alignment in this region. If we're most interested in the skull, using 1480. Best grid may be a combined grid. Form of adaptive imaging, feeding CudaEngine, modify grid based on what we learn. Got an image, isolate an image, modify the speed of sound based on the intensity of the echoes. Strong reflectors. Aligning the speed of sound better. Correct geometrical distance. Structure that we have. Cuda engine doesn't care; just sees a table of delays associated with grid points. It can compute a homogeneous profile, can modify to account for whatever we learn about the system.\n",
    "\n",
    "Start cuda engine with a grid, acquire data, isolate the skull, and start modifying the delays with the grid by what we discover. Use knowledge of anatomy. Use what we know with the speed of sound. Incorperate density. Have the speed of sound. Compute a correction for the delay. Send another grid modified  by what we just learned. We downloaded a grid, can use an initial grid, can ask for the grid back, modify, push it back. \n",
    "\n",
    "For thos grid points, can go with 1520, higher speed of sound. We can compute the same discritization. Andy chose to use FieldII. If we can get something like this, we can compute some predistortions for the beam. We can find the expected gain for the system. Given the results for the system, the STF images, they're the screen capture images. They did not correct for the offset.\n",
    "\n",
    "Increase the aline offset. Not just a positional thing. What we interpret to be the echo is effectively wrong. We want to establish where the echo is. If we don't get a good STF image. There is a beamforming solution to this. Matched filter is an option. INverse filter. Download an array. Do not have the inverse code. \n",
    "\n",
    "We'll be measring complex impedance. With short pulse, we don't be able to decompose. We still get the well-behaved the profile of the pulses. Validated with simulated. 5 foci at 0 +- 0.5 to 1 degree, synthesized independently. This is the simplest form of wavefront synthesis. Transmitting power at the points. Idea talking about, resynthesizing them. We're not working in a vaccuum. I can play all kinds of games this way. Create all kinds of permutations. Full bandwidth at all points. Not losing bandwidth. Different trnamsmissoin, different speckles. Started working, can be done more methodically. We're adding energy from transmission. Broadening bandwidth we're working, destructive interference where we're working at. Ultimately each point, using 5 frequencies, adding up to 3% overlap, using broader bandwidth for the transducer. Don't have to send one transmission to the next. Broadband reconstruction. When you have enough energy at any tomographic reconstruction, it will \"come to life\". Implement in practical and real time. \n",
    "\n",
    "People have talked about tomography for a long time. Becoming reality. Beamforming leading to tomography. No one has done this. For thie first paper, can we validate. Implement with the offset and the matched filter (important so we can mix frequencies). Multiband refocusing. Randomize phases to get a well-behaved waveform. With the matched filtering and the proper offset, it will be immediate. This paper. If there is a misalignment, results in echogenicity.\n",
    "\n",
    "Installing it, bunch of programs. Focusing on the combining transmission and reflection in the setup, but also in hydrophone experiments, modification of the speed of sound. Because we're working towards reconstruction, more immediately applicable. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
